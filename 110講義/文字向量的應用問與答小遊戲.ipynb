{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"文字向量的應用問與答小遊戲.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EsRPnTynZ-T4"},"source":["## 安裝及載入jieba與gensim下之word2vec模組"]},{"cell_type":"code","metadata":{"id":"aUsX3eNp622l"},"source":["!pip install jieba\n","!pip install gensim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcczSdiHwGS1"},"source":["步驟一：先將檔案中已訓練好的詞向量放入名為word_vecs這個詞典中"]},{"cell_type":"code","metadata":{"id":"7q5TqkFqwMvV"},"source":["# -*- coding: utf-8 -*-\n","import numpy as np # 安裝numpy\n","\n","dim = 0 #假設一個變數名字是維度\n","word_vecs= {}\n","# 開啟詞向量檔案\n","with open('cna.cbow.cwe_p.tar_g.512d.0.txt') as f:\n","  for line in f:\n","    # 假設我們的詞向量有512維度\n","    # 由word以及其向量數值共513行\n","    # 以空格分隔組成詞向量檔案中一行\n","    tokens = line.strip().split() #依空白作為分隔\n","\n","    # 第一行是兩個整數，分別代表有幾個詞向量，以及詞向量維度\n","    if len(tokens) == 2:\n","      dim = int(tokens[1])\n","      continue\n","    \n","    word = tokens[0] \n","    vec = np.array([ float(t) for t in tokens[1:] ])\n","    word_vecs[word] = vec\n","\n","# 之後可以從word_vecs這個dict中取得詞向量"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnFzgeNSu9m9"},"source":["word_vecs[\"企業\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_Uwp7E7DJeW"},"source":["import jieba\n","import numpy as np\n","dialogue = \"台南市長是哪一個政黨\"\n","answers = [\n","  \"今天天氣是晴天\",  \n","  \"台南市長是民進黨\",\n","  \"我喜歡吃美食\", \n","  \"我喜歡打羽球\",\n","  \"我就讀中信金融管理學院\",\n","  \"台南最有名的夜市式花園夜市\"]\n","\n","emb_cnt = 0 #計算一個句子有幾個詞，以作為計算平均值之用\n","avg_dlg_emb = np.zeros((dim,))\n","# jieba.cut 會把dialogue作分詞\n","# 對於有在word_vecs裡面的詞我們才把它取出\n","# 最後詞向量加總取平均，作為句子的向量表示\n","for word in jieba.cut(dialogue):\n","  if word in word_vecs:\n","    avg_dlg_emb += word_vecs[word]\n","    emb_cnt += 1\n","avg_dlg_emb /= emb_cnt\n","\n","emb_cnt = 0\n","max_idx = -1\n","max_sim = -10\n","# 在六個回答中，每個答句都取詞向量平均作為向量表示\n","# 我們選出與dialogue句子向量表示cosine similarity最高的短句\n","for idx,ans in enumerate(answers):\n","  avg_ans_emb = np.zeros((dim,))\n","  for word in jieba.cut(ans):\n","    if word in word_vecs:\n","      avg_ans_emb += word_vecs[word]\n","      emb_cnt += 1\n","  sim = np.dot(avg_dlg_emb, avg_ans_emb) / np.linalg.norm(avg_dlg_emb) / np.linalg.norm(avg_ans_emb)\n","#算出相似性\n","  print(\"Ans#%d: %f\" % (idx+1, sim))\n","  if sim > max_sim:\n","    max_idx = idx+1\n","    max_sim = sim\n","\n","print(\"Answer:%d\" % max_idx)\n","print(answers[max_idx-1])"],"execution_count":null,"outputs":[]}]}